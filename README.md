# Voice Chatbot - Local AI Assistant ğŸ™ï¸ğŸ¤–

A fully local voice chatbot powered by AI, featuring real-time speech-to-text, LLM conversation, and text-to-speech synthesis. Optimized for AMD Ryzen 7 + NVIDIA RTX 4060 (8GB VRAM).

## Features âœ¨

- **ğŸ¤ Real-time Voice Input**: Continuous listening with Voice Activity Detection (VAD)
- **ğŸ§  Smart Conversations**: Powered by Llama3 via Ollama
- **ğŸ”Š Natural Speech Output**: High-quality TTS with Kokoro ONNX
- **ğŸ¨ Modern Dark UI**: WhatsApp/iMessage-style chat bubbles
- **âš¡ Multi-threaded**: Non-blocking UI with efficient resource usage
- **ğŸ” Feedback Prevention**: Automatic microphone muting during bot speech

## Architecture ğŸ—ï¸

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            PyQt6 GUI (Main Thread)          â”‚
â”‚  - Chat bubbles (user/bot)                  â”‚
â”‚  - Status indicator                         â”‚
â”‚  - Control buttons                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
       â”‚               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Listener   â”‚ â”‚    Worker     â”‚
â”‚    Thread    â”‚ â”‚    Thread     â”‚
â”‚              â”‚ â”‚               â”‚
â”‚ - Mic input  â”‚ â”‚ - Transcribe  â”‚
â”‚ - VAD        â”‚ â”‚ - LLM         â”‚
â”‚              â”‚ â”‚ - TTS         â”‚
â”‚              â”‚ â”‚ - Playback    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Installation ğŸ“¦

### 1. Prerequisites

- **Python**: 3.10 or 3.11 (recommended)
- **CUDA**: 11.8+ for GPU acceleration
- **Ollama**: Installed and running ([Download here](https://ollama.ai))

### 2. Install Ollama Model

```bash
ollama pull llama3
```

### 3. Python Dependencies

```bash
pip install -r requirements.txt
```

### 4. Model Files Setup

Place the following files in the project root directory:

```
ChatbotAI-English/
â”œâ”€â”€ kokoro-v0_19.onnx    # Kokoro TTS model (already present)
â”œâ”€â”€ voices.json           # Voice configurations (already present)
â”œâ”€â”€ main.py
â”œâ”€â”€ ai_manager.py
â”œâ”€â”€ audio_utils.py
â”œâ”€â”€ styles.py
â””â”€â”€ requirements.txt
```

**Note**: The `kokoro-v0_19.onnx` and `voices.json` files should already be in your workspace.

## Usage ğŸš€

### Run the Application

```bash
python main.py
```

### How It Works

1. **Click "Start Listening"** (or wait for auto-start)
2. **Speak into your microphone** in English
3. **The bot will**:
   - Transcribe your speech (Whisper)
   - Process with Llama3 (Ollama)
   - Generate voice response (Kokoro)
   - Play the audio back
4. **Repeat**: The bot continues listening after speaking

### Controls

- **Start Listening**: Begin voice interaction
- **Stop**: Pause all processing
- **Clear Chat**: Reset conversation history

## Configuration âš™ï¸

### Adjust Models (in `ai_manager.py`)

```python
ai_manager = AIManager(
    whisper_model="base.en",      # Options: tiny.en, base.en, small.en
    ollama_model="llama3",         # Any Ollama model
    voice_name="af_bella"          # Options: af_bella, af_sarah
)
```

### Adjust VAD Sensitivity (in `audio_utils.py`)

```python
recorder = AudioRecorder(
    silence_threshold=0.015,   # Lower = more sensitive
    silence_duration=1.5       # Seconds of silence before stop
)
```

### Change UI Colors (in `styles.py`)

Modify the `DARK_STYLE` CSS variables:
- Background: `#121212`
- User bubble: `#005C4B`
- Bot bubble: `#1F1F1F`

## Project Structure ğŸ“

```
â”œâ”€â”€ main.py              # Main application & GUI logic
â”œâ”€â”€ ai_manager.py        # AI model management (Whisper, Ollama, Kokoro)
â”œâ”€â”€ audio_utils.py       # Audio recording & playback with VAD
â”œâ”€â”€ styles.py            # PyQt6 QSS dark theme styles
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ README.md            # This file
â”œâ”€â”€ kokoro-v0_19.onnx   # Kokoro TTS model
â””â”€â”€ voices.json          # Voice configurations
```

## Performance Tips ğŸ¯

### For 8GB VRAM

- Use `base.en` or `small.en` for Whisper (not `medium` or `large`)
- Keep conversation history to 10 messages max (already configured)
- Close other GPU-intensive applications

### Troubleshooting

**GPU Not Detected**:
```bash
# Check CUDA availability
python -c "import torch; print(torch.cuda.is_available())"
```

**Ollama Connection Error**:
```bash
# Ensure Ollama is running
ollama list
```

**Microphone Not Working**:
```bash
# Test audio devices
python -c "import sounddevice as sd; print(sd.query_devices())"
```

## Technical Details ğŸ”§

### Audio Pipeline

- **Input**: 16 kHz, mono, float32
- **VAD**: RMS-based energy detection
- **Feedback Prevention**: Microphone paused during TTS playback

### AI Models

- **STT**: faster-whisper (base.en) on CUDA with FP16
- **LLM**: Ollama llama3 with streaming disabled
- **TTS**: Kokoro ONNX (24 kHz output) on CUDA

### Threading Model

- **Main Thread**: UI updates only (PyQt6)
- **Listener Thread**: Continuous audio capture
- **Worker Thread**: STT â†’ LLM â†’ TTS pipeline

## License ğŸ“„

This project uses various open-source models and libraries. Please review individual licenses:

- **faster-whisper**: MIT License
- **Ollama**: MIT License
- **Kokoro TTS**: Check model provider's license
- **PyQt6**: GPL v3

## Credits ğŸ‘

- **Whisper**: OpenAI
- **Llama3**: Meta AI
- **Kokoro TTS**: [Model provider]
- **Ollama**: Ollama team

---

**Enjoy your local AI voice assistant! ğŸ‰**
